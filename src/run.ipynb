{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD Radeon RX 6700S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "dataset: icewsmall\n",
      "epoch: 20\n",
      "batch_size: 32\n",
      "dim: 64\n",
      "l2: 1e-07\n",
      "lr: 0.005\n",
      "feature_type: id\n",
      "use relational context: True\n",
      "context_hops: 3\n",
      "neighbor_samples: 8\n",
      "neighbor_agg: cross\n",
      "use relational path: True\n",
      "max_path_len: 3\n",
      "path_type: embedding\n",
      "=============================================\n",
      "\n",
      "reading entity dict and relation dict ...\n",
      "reading train, validation, and test data ...\n",
      "processing the temporal knowledge graph ...\n",
      "loading paths from files ...\n",
      "transforming paths to one hot IDs ...\n",
      "start training ...\n",
      "/home/bisco/github/PathConX/src/train.py:123: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)\n",
      "  feed_dict[\"path_features\"] = torch.sparse.FloatTensor(indices.t(), values, torch.Size(shape)).to_dense()\n",
      "epoch  0   train acc: 0.4648   valid acc: 0.2263   test acc: 0.2170\n",
      "           mrr: 0.4357   mr: 14.9982   h1: 0.3060   h3: 0.4783   h5: 0.5795\n",
      "\n",
      "epoch  1   train acc: 0.5534   valid acc: 0.2246   test acc: 0.2096\n",
      "           mrr: 0.4338   mr: 15.7607   h1: 0.3016   h3: 0.4770   h5: 0.5839\n",
      "\n",
      "epoch  2   train acc: 0.6124   valid acc: 0.2422   test acc: 0.2158\n",
      "           mrr: 0.4367   mr: 15.4658   h1: 0.3069   h3: 0.4770   h5: 0.5837\n",
      "\n",
      "epoch  3   train acc: 0.6393   valid acc: 0.2386   test acc: 0.2362\n",
      "           mrr: 0.4560   mr: 14.4554   h1: 0.3261   h3: 0.5069   h5: 0.6040\n",
      "\n",
      "epoch  4   train acc: 0.6857   valid acc: 0.2364   test acc: 0.2252\n",
      "           mrr: 0.4263   mr: 16.3422   h1: 0.3071   h3: 0.4594   h5: 0.5554\n",
      "\n",
      "epoch  5   train acc: 0.7022   valid acc: 0.2471   test acc: 0.2453\n",
      "           mrr: 0.4414   mr: 16.4667   h1: 0.3239   h3: 0.4804   h5: 0.5632\n",
      "\n",
      "epoch  6   train acc: 0.7199   valid acc: 0.2475   test acc: 0.2420\n",
      "           mrr: 0.4464   mr: 16.5145   h1: 0.3355   h3: 0.4719   h5: 0.5569\n",
      "\n",
      "epoch  7   train acc: 0.7356   valid acc: 0.2433   test acc: 0.2408\n",
      "           mrr: 0.4288   mr: 17.8531   h1: 0.3210   h3: 0.4576   h5: 0.5420\n",
      "\n",
      "epoch  8   train acc: 0.7503   valid acc: 0.2371   test acc: 0.2417\n",
      "           mrr: 0.4170   mr: 18.1942   h1: 0.3038   h3: 0.4473   h5: 0.5382\n",
      "\n",
      "epoch  9   train acc: 0.7650   valid acc: 0.2326   test acc: 0.2342\n",
      "           mrr: 0.4272   mr: 18.3879   h1: 0.3225   h3: 0.4531   h5: 0.5373\n",
      "\n",
      "epoch 10   train acc: 0.7558   valid acc: 0.1935   test acc: 0.2002\n",
      "           mrr: 0.3858   mr: 19.4547   h1: 0.2815   h3: 0.4096   h5: 0.4824\n",
      "\n",
      "epoch 11   train acc: 0.7623   valid acc: 0.2214   test acc: 0.2121\n",
      "           mrr: 0.4055   mr: 19.0022   h1: 0.2973   h3: 0.4308   h5: 0.5170\n",
      "\n",
      "epoch 12   train acc: 0.7692   valid acc: 0.2201   test acc: 0.2103\n",
      "           mrr: 0.3921   mr: 19.6379   h1: 0.2853   h3: 0.4141   h5: 0.5007\n",
      "\n",
      "epoch 13   train acc: 0.7795   valid acc: 0.2203   test acc: 0.2145\n",
      "           mrr: 0.3998   mr: 19.5431   h1: 0.2931   h3: 0.4281   h5: 0.5027\n",
      "\n",
      "epoch 14   train acc: 0.7956   valid acc: 0.2371   test acc: 0.2257\n",
      "           mrr: 0.4073   mr: 19.4696   h1: 0.3011   h3: 0.4328   h5: 0.5179\n",
      "\n",
      "epoch 15   train acc: 0.7904   valid acc: 0.2179   test acc: 0.2121\n",
      "           mrr: 0.3935   mr: 19.8741   h1: 0.2879   h3: 0.4136   h5: 0.5036\n",
      "\n",
      "epoch 16   train acc: 0.7865   valid acc: 0.2176   test acc: 0.2054\n",
      "           mrr: 0.3846   mr: 19.9931   h1: 0.2759   h3: 0.4080   h5: 0.4944\n",
      "\n",
      "epoch 17   train acc: 0.7804   valid acc: 0.2107   test acc: 0.2078\n",
      "           mrr: 0.3915   mr: 19.7978   h1: 0.2859   h3: 0.4210   h5: 0.4980\n",
      "\n",
      "epoch 18   train acc: 0.7974   valid acc: 0.2136   test acc: 0.2074\n",
      "           mrr: 0.3933   mr: 20.4234   h1: 0.2911   h3: 0.4183   h5: 0.4933\n",
      "\n",
      "epoch 19   train acc: 0.8005   valid acc: 0.2217   test acc: 0.2183\n",
      "           mrr: 0.3874   mr: 21.0826   h1: 0.2893   h3: 0.4051   h5: 0.4857\n",
      "\n",
      "final results\n",
      "acc: 0.2420   mrr: 0.4464   mr: 16.5145   h1: 0.3355   h3: 0.4719   h5: 0.5569\n"
     ]
    }
   ],
   "source": [
    "!python3 tkgmain.py --cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alt + A\n"
     ]
    }
   ],
   "source": [
    "print('Alt + A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
